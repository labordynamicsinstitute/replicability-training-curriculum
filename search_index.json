[["index.html", "TRAINING For Reproducibility Verification Chapter 1 Tentative Agenda 1.1 How to read this document", " TRAINING For Reproducibility Verification Lars Vilhuber Meredith Welch David Wasser 2020-08-21 Chapter 1 Tentative Agenda Items that are bolded are joint with the Computational Tools for Social Scientists Workshop (for graduate students). Items in italics are optional. Time Aug 24 Aug 25 Aug 26 Aug 27 Aug 28 1:00 (1:30) Welcome to LDI Lab Coffee hour: What does the AEA Data and Code Availability policy imply for an economist's research? 2:00 Intro to: Reproducible practices Breakout groups: debugging software and accounts (reserved for working on test articles) (reserved for working on test articles) (reserved for working on test articles) 3:00 Reproducible practices, data citation A prototypical replication report Small group peer mentoring Small group peer mentoring Follow-up on test articles (whole group) 4:00 A Markdown reproducible report with Stata and R A walkthrough of the workflow for unpublished articles (reserved for working on test articles) (reserved for working on test articles) 5:00 What will you be doing in the Lab Basics and advanced version control (reserved for working on test articles) (reserved for working on test articles) Training will occur virtually, through a combination of required self-study and live Zoom meetings. The live part of the training will take place Aug 24, Aug 25, and Aug 28, 2020. If your application to the LDI Replication Lab was accepted, you will be receiving a calendar invite with the Zoom information soon. All the remaining information here is open to anybody. Content is . 1.1 How to read this document If you are a casual reader of this document, start with the pre-requisites. If you are a student participating in our training, then start with the pre-training tasks. "],["pre-requisites.html", "Chapter 2 Pre-requisites", " Chapter 2 Pre-requisites Most students with some prior experience with statistical software can effectively reproduce and assess articles. In economics, most articles use either Stata or Matlab. Software in economics Students should be comfortable working on a variety of computers, including their own, and be flexible with respect to the location of computing. If you don't know what that means, you'll find out during training! "],["pre-training.html", "Chapter 3 Pre-training tasks", " Chapter 3 Pre-training tasks We ask that trainees accomplish a few tasks prior to the first training session. Please do the following: The training is virtual, using video, and we frequently meet virtually. Please review our Video Etiquette rules (they are useful beyond our group as well) View my recent talk on the background of the lab), including what we do, and why we do it. Review our Privacy Policy, where you will recognize how we handle your privacy, and the privacy of authors. Go through our Setup Checklist and install necessary software "],["background.html", "Chapter 4 Background 4.1 Activities of the LDI Replication Lab 4.2 Learning goals", " Chapter 4 Background On July 16, 2019, the AEA announced an updated &quot;Data and Code Availability Policy&quot; (American Economic Association 2019; American Economic Association 2020). Henceforth, replication materials must be made available to the AEA prior to acceptance - previously, it was prior to publication, but after acceptance. Computer code should be provided for all stages of the data cleaning and data analysis (code for the data cleaning portion was previously optional). Raw data must be uniformly made available, when permissions allow (also for author-collected survey data, data from experiments). For restricted-access or proprietary data, to the extent permissible, the data must be made available to the AEA Data Editor for verification, even if the data cannot be published by the author.1 Enforcement of an existing but unenforced data citation requirement as per AEA Citation Guidelines. We also test licenses, access restrictions, and sometimes question the ability of authors to publish the data. We have had cases both ways: data provided after initial refusal, and data rejected by us because the license did not allow distribution. For now, we also check for obvious personally identifiable information (PII). However, the ultimate responsibility lies with authors. All data and code must be available in a &quot;trusted repository,&quot; which in most cases means the AEA's Data and Code Repository at openICPSR, for better transparency and findability. ZIP files are no longer accepted as supplementary packages, and we check that. Supplements are tagged with JEL codes, other keywords (e.g., Current Population Survey'' orbehavioral study''), and optionally with methodological information (time period, geographic region, survey method used). Each deposit gets its own DOI - a permanent unique identifier. Deposits can be found through various search engines, such as the native search engine on openICPSR, through Google Data Search or through DOI registries such as DataCite. To implement all this, we built a system using Jira, and connect to it from ScholarOne (system used for manuscript submission) and openICPSR. 4.1 Activities of the LDI Replication Lab The LDI Replication Lab conducts reproducibility checks in two way. 4.1.1 Pre-Publication Evaluation of Reproducibility and Quality of Supplemental Materials The Lab performs pre-publication evaluation for the American Economic Association, i.e., prior to publication. Think of it as a &quot;reviewer&quot; of the data supplement. Analyze the provided materials - see Verification guidance Verify data citations Verify ability to post data (do the authors have the right to post the data?) If possible, attempt replication 4.1.2 Post-Publication Evaluation of Reproducibility We download articles and supplements, assess to what extent an undergraduate student can run the code that produces the analysis reported in the paper. We have also in the past done an evaluation of the response of authors when the code is only available &quot;upon request&quot;. Not currently an active project. This is a secondary goal, as time permits or as research goals suggest. It is quite similar to the first goal, but there is no interaction with authors, and no method to improve authors' files. Interested parties might visit ACRE for how to incorporate this kind of activity into a class curriculum. 4.2 Learning goals In this training, you will learn how to verify compliance with the policy. This means going through a variety of checklists, obtaining data, and running code, as per instructions provided by authors. You will not be required to actively program, but you will learn a lot about how to program (and sometimes, how not to program). You will gain an appreciation for a well-structured empirical analysis, which you will benefit from for your own studies (now) and in your work (after graduation). References "],["basic-concepts.html", "Chapter 5 Basic Concepts 5.1 Data citations and data availability statements 5.2 Generic data workflow 5.3 Assessing computational reproducibility", " Chapter 5 Basic Concepts The goal thus of the reproducibility activity is to verify provenance of all data sources, to verify the availability of all computer code to produce analysis files from data sources, and to produce tables, figures, and in-text numbers from analysis files, to verify that the available code actually reproduces the analysis files, tables, figures, and in-text numbers. We therefore need to define a few concepts: what is a data source, and how can one verify its provenance? what is analysis data? how can we verify computational reproducibility? 5.1 Data citations and data availability statements 5.2 Generic data workflow graph TD; subgraph Dataflow; A((Input data)) ==&gt; B[Cleaning programs]; B ==&gt; C((Analysis data)); C ==&gt; D[Analysis programs] D ==&gt; E((Outputs)); end; B -.-&gt; F((&quot;Auxiliary data(created)&quot;)); F -.-&gt; C; Z((Source)) -.-&gt; X[Data citation] -.-&gt; A; 5.3 Assessing computational reproducibility "],["privacy.html", "A Privacy A.1 Privacy of Replicators A.2 The Privacy of Authors", " A Privacy We need to cover two sorts of privacy: the privacy of those whose materials we verify, and your own privacy. There are limitations to both, but we attempt to protect privacy as much as possible. A.1 Privacy of Replicators You are tasked with reproducing articles. Much as referees for journals mostly remain anonymous, we want you to remain anonymous as well. You may reveal yourself to authors later (after the task is completed), if you wish. You should not contact authors unless authorized by the Lab Leader. Normally, all such communications go through the Lab Leader. We do name you (to thank you) in the annual report, but do not attribute your work to any one article. In the empirical analysis of all the articles, we replace your netid and name with an anonymous (and untraceable) identifier. So we can track that you have done Articles A1, D57, and Z31, but nobody knows that it was you. There is &quot;leakage&quot; of information: In order to download materials, you need to login to openICPSR, and have the ability to download from specific deposits. This does reveal your name to the depositors. This is currently a technological constraint, and cannot be avoided without great complications. If you have concerns, please let us know, and we will find a workaround. Should you ever be contacted in some unacceptable fashion by authors, you should immediately contact the Lab Leadership. You can, and you should, reveal your affiliation with this project! You can (and you should) be proud of the work you will do or have done, and you are allowed (and you should) reference this project as an accomplishment. A.2 The Privacy of Authors When we do pre-publication verification, this is equally important. You are never allowed to reveal that the author has submitted to the journal This includes when you need to contact third parties for materials that are part of the replication materials. In case of doubt, contact Lab Leadership. You are never allowed to reveal anything about the analysis that the author is conducting, and that you are reproducing, to anybody outside of this group. You must never put the code, the article, or the data on a location where others outside of this group could access it Bitbucket within the aeaverification project is OK, do not attempt to make a repository public (even if it may seem convenient not to have to enter your login etc.) Remove the files from your laptop as soon as you are done with it (after git push, of course) You may remove them from CISER nodes, but those will be cleansed later Do not email or otherwise disseminate (twitter, facebook, snapchat, whatever) the files received, or any other information about the papers "],["checklist.html", "B Setup Checklist B.1 Accounts you will need to sign up for (action required) B.2 Accounts you will be signed up for (no action required) B.3 Software to install on your laptop B.4 Text editor vs. Word processor B.5 Availability and Suggestions B.6 Note B.7 Help", " B Setup Checklist B.1 Accounts you will need to sign up for (action required) [ ] CISER account (for computing access) - Select &quot;Apply for Research account&quot; and list Lars as a sponsor. Do not select &quot;Request Secure Data Services account&quot;. If prompted about using sensitive or restricted data, please select &quot;No&quot;. Otherwise, this will take you to a window to sign up for a CRADC account instead, which is not necessary. If you encounter this issue, please email the CISER help desk asking them cancel the CRADC account request. If using a Mac and if &quot;Microsoft Remote Desktop&quot; is not already installed on Mac, install Remote Desktop Software from iTunes (not necessary on Windows, as it is pre-installed) Once an account is set up, learn How to log on to CISER (also includes download links) [ ] You will need openICPSR account, in order to download pre-publication materials. Please be sure to use your Cornell e-mail! B.2 Accounts you will be signed up for (no action required) [ ] Atlassian account Bitbucket for access to the internal Git repos Jira account for the internal issue tracker [x] Email is used for the mailing list ldi-lab-l@cornell.edu B.3 Software to install on your laptop [x] Command line (PowerShell, or Terminal, your choice) - pre-installed [ ] Windows Remote Desktop (see above) [ ] Git command line tool (download the software, then follow the guide on Installing Git on your computer [ ] Visual Studio Code (download location), a powerful text editor [ ] Sourcetree (Git graphical interface optimized for Bitbucket) download location (OPTIONAL) Other software is optional. You will use statistical software on other computers that we will get you access to. B.4 Text editor vs. Word processor You want to use a text editor, not a word processor. The difference: a text editor creates simple text files, without fancy formatting. If you are creating code in Stata, Matlab, or Rstudio, you are using a customized text editor, sometimes called an IDE = &quot;Integrated Development Environment&quot;. That is OK. But remember that all such program code is a straight text file. General purpose text editors can view and edit them all, although they may lack some of the fancy features that make programming easier in the dedicated IDE. B.5 Availability and Suggestions OS Laptop CISER Custom node MS Visual Studio Code All Suggested Yes Atom All Yes Notepad++ Windows Yes Yes vi Mac, Linux B.6 Note Our preferred editor (Visual Studio Code) is not available on CISER nodes. However, it is possible to install, though a bit tricky (advanced). B.7 Help Git cheatsheet and another one Markdown cheatsheet "]]
